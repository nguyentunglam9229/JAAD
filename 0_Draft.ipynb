{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0_Draft.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbUYkT40lhm3","executionInfo":{"status":"ok","timestamp":1611223383303,"user_tz":-420,"elapsed":33966,"user":{"displayName":"Toni Vu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6uIu6Vcgzta1ovHLLOvVj5RVWGexlxO7F_N4c=s64","userId":"18061882157352491166"}},"outputId":"ecb2f2c1-0bbc-4eee-f304-cd6d0d4865c3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r1BfH4tEHH7S","executionInfo":{"status":"ok","timestamp":1611223390600,"user_tz":-420,"elapsed":747,"user":{"displayName":"Toni Vu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6uIu6Vcgzta1ovHLLOvVj5RVWGexlxO7F_N4c=s64","userId":"18061882157352491166"}}},"source":["import os\r\n","os.chdir('/content/drive/MyDrive/NLP_and_CV_Projects/CV/Model/YOWO/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Sm4QwGwIle0q","executionInfo":{"status":"ok","timestamp":1610013325086,"user_tz":-420,"elapsed":768,"user":{"displayName":"Vu Nghia","photoUrl":"","userId":"06396789043579285095"}},"outputId":"ff5941f9-3320-4a25-f15a-ee084cea8e7c"},"source":["pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/NLP_and_CV_Projects/CV/Tuyen/YOWO'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"j1AMg2JGGv05"},"source":["import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1rec8RlAl76D","executionInfo":{"status":"ok","timestamp":1609330844588,"user_tz":-420,"elapsed":604,"user":{"displayName":"Vu Nghia","photoUrl":"","userId":"06396789043579285095"}},"outputId":"94bb7391-74ad-4692-c0ac-be3dd42c329a"},"source":["torch.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.7.0+cu101'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"FwcB6esVxnxK"},"source":["# Test 2D branch"]},{"cell_type":"code","metadata":{"id":"rxlTgdA0xs_k"},"source":["# !wget http://pjreddie.com/media/files/yolo.weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I38dgIfgk6ZC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610013388119,"user_tz":-420,"elapsed":2622,"user":{"displayName":"Vu Nghia","photoUrl":"","userId":"06396789043579285095"}},"outputId":"39b141f6-209c-4338-b7d5-592d0a426f18"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import numpy as np\r\n","from region_loss import RegionLoss\r\n","from cfg import *\r\n","#from layers.batchnorm.bn import BN2d\r\n","\r\n","class MaxPoolStride1(nn.Module):\r\n","    def __init__(self):\r\n","        super(MaxPoolStride1, self).__init__()\r\n","\r\n","    def forward(self, x):\r\n","        x = F.max_pool2d(F.pad(x, (0,1,0,1), mode='replicate'), 2, stride=1)\r\n","        return x\r\n","\r\n","class Reorg(nn.Module):\r\n","    def __init__(self, stride=2):\r\n","        super(Reorg, self).__init__()\r\n","        self.stride = stride\r\n","    def forward(self, x):\r\n","        stride = self.stride\r\n","        assert(x.data.dim() == 4)\r\n","        B = x.data.size(0)\r\n","        C = x.data.size(1)\r\n","        H = x.data.size(2)\r\n","        W = x.data.size(3)\r\n","        assert(H % stride == 0)\r\n","        assert(W % stride == 0)\r\n","        ws = stride\r\n","        hs = stride\r\n","        x = x.view(B, C, H//hs, hs, W//ws, ws).transpose(3,4).contiguous()\r\n","        x = x.view(B, C, H//hs*W//ws, hs*ws).transpose(2,3).contiguous()\r\n","        x = x.view(B, C, hs*ws, H//hs, W//ws).transpose(1,2).contiguous()\r\n","        x = x.view(B, hs*ws*C, H//hs, W//ws)\r\n","        return x\r\n","\r\n","class GlobalAvgPool2d(nn.Module):\r\n","    def __init__(self):\r\n","        super(GlobalAvgPool2d, self).__init__()\r\n","\r\n","    def forward(self, x):\r\n","        N = x.data.size(0)  # num of observations/ batch size?\r\n","        C = x.data.size(1)  # num of channels\r\n","        H = x.data.size(2)  # height\r\n","        W = x.data.size(3)  # width\r\n","        x = F.avg_pool2d(x, (H, W))\r\n","        x = x.view(N, C)\r\n","        return x\r\n","\r\n","# for route and shortcut\r\n","class EmptyModule(nn.Module):\r\n","    def __init__(self):\r\n","        super(EmptyModule, self).__init__()\r\n","\r\n","    def forward(self, x):\r\n","        return x\r\n","\r\n","# support route shortcut and reorg\r\n","class Darknet(nn.Module):\r\n","    def __init__(self, cfgfile):\r\n","        super(Darknet, self).__init__()\r\n","        self.blocks = parse_cfg(cfgfile)\r\n","        self.models = self.create_network(self.blocks) # merge conv, bn,leaky\r\n","        self.loss = self.models[len(self.models)-1]\r\n","\r\n","        self.width = int(self.blocks[0]['width'])\r\n","        self.height = int(self.blocks[0]['height'])\r\n","\r\n","        if self.blocks[(len(self.blocks)-1)]['type'] == 'region':\r\n","            self.anchors = self.loss.anchors\r\n","            self.num_anchors = self.loss.num_anchors\r\n","            self.anchor_step = self.loss.anchor_step\r\n","            self.num_classes = self.loss.num_classes\r\n","\r\n","        self.header = torch.IntTensor([0,0,0,0])\r\n","        self.seen = 0\r\n","\r\n","    def forward(self, x):\r\n","        ind = -2\r\n","        self.loss = None\r\n","        outputs = dict()\r\n","        for block in self.blocks:\r\n","            ind = ind + 1\r\n","            #if ind > 0:\r\n","            #    return x\r\n","\r\n","            if block['type'] == 'net':\r\n","                continue\r\n","            elif block['type'] == 'convolutional' or block['type'] == 'maxpool' or block['type'] == 'reorg' or block['type'] == 'avgpool' or block['type'] == 'softmax' or block['type'] == 'connected':\r\n","                x = self.models[ind](x)\r\n","                outputs[ind] = x\r\n","            elif block['type'] == 'route':\r\n","                layers = block['layers'].split(',')\r\n","                layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\r\n","                if len(layers) == 1:\r\n","                    x = outputs[layers[0]]\r\n","                    outputs[ind] = x\r\n","                elif len(layers) == 2:\r\n","                    x1 = outputs[layers[0]]\r\n","                    x2 = outputs[layers[1]]\r\n","                    x = torch.cat((x1,x2),1)\r\n","                    outputs[ind] = x\r\n","            elif block['type'] == 'shortcut':\r\n","                from_layer = int(block['from'])\r\n","                activation = block['activation']\r\n","                from_layer = from_layer if from_layer > 0 else from_layer + ind\r\n","                x1 = outputs[from_layer]\r\n","                x2 = outputs[ind-1]\r\n","                x  = x1 + x2\r\n","                if activation == 'leaky':\r\n","                    x = F.leaky_relu(x, 0.1, inplace=True)\r\n","                elif activation == 'relu':\r\n","                    x = F.relu(x, inplace=True)\r\n","                outputs[ind] = x\r\n","            elif block['type'] == 'region':\r\n","                continue\r\n","                print(\"LOSSS\")\r\n","            elif block['type'] == 'cost':\r\n","                continue\r\n","            else:\r\n","                print('unknown type %s' % (block['type']))\r\n","        # print(x.shape)\r\n","        return x\r\n","\r\n","    def print_network(self):\r\n","        print_cfg(self.blocks)\r\n","\r\n","    def create_network(self, blocks):\r\n","        models = nn.ModuleList()\r\n","    \r\n","        prev_filters = 3\r\n","        out_filters =[]\r\n","        conv_id = 0\r\n","        for block in blocks:\r\n","            if block['type'] == 'net':\r\n","                prev_filters = int(block['channels'])\r\n","                continue\r\n","            elif block['type'] == 'convolutional':\r\n","                conv_id = conv_id + 1\r\n","                batch_normalize = int(block['batch_normalize'])\r\n","                filters = int(block['filters'])\r\n","                kernel_size = int(block['size'])\r\n","                stride = int(block['stride'])\r\n","                is_pad = int(block['pad'])\r\n","                pad = (kernel_size-1)//2 if is_pad else 0\r\n","                activation = block['activation']\r\n","                model = nn.Sequential()\r\n","                if batch_normalize:\r\n","                    model.add_module('conv{0}'.format(conv_id), nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=False))\r\n","                    model.add_module('bn{0}'.format(conv_id), nn.BatchNorm2d(filters))\r\n","                    #model.add_module('bn{0}'.format(conv_id), BN2d(filters))\r\n","                else:\r\n","                    model.add_module('conv{0}'.format(conv_id), nn.Conv2d(prev_filters, filters, kernel_size, stride, pad))\r\n","                if activation == 'leaky':\r\n","                    model.add_module('leaky{0}'.format(conv_id), nn.LeakyReLU(0.1, inplace=True))\r\n","                elif activation == 'relu':\r\n","                    model.add_module('relu{0}'.format(conv_id), nn.ReLU(inplace=True))\r\n","                prev_filters = filters\r\n","                out_filters.append(prev_filters)\r\n","                models.append(model)\r\n","            elif block['type'] == 'maxpool':\r\n","                pool_size = int(block['size'])\r\n","                stride = int(block['stride'])\r\n","                if stride > 1:\r\n","                    model = nn.MaxPool2d(pool_size, stride)\r\n","                else:\r\n","                    model = MaxPoolStride1()\r\n","                out_filters.append(prev_filters)\r\n","                models.append(model)\r\n","            elif block['type'] == 'avgpool':\r\n","                model = GlobalAvgPool2d()\r\n","                out_filters.append(prev_filters)\r\n","                models.append(model)\r\n","            elif block['type'] == 'softmax':\r\n","                model = nn.Softmax()\r\n","                out_filters.append(prev_filters)\r\n","                models.append(model)\r\n","            elif block['type'] == 'cost':\r\n","                if block['_type'] == 'sse':\r\n","                    model = nn.MSELoss(size_average=True)\r\n","                elif block['_type'] == 'L1':\r\n","                    model = nn.L1Loss(size_average=True)\r\n","                elif block['_type'] == 'smooth':\r\n","                    model = nn.SmoothL1Loss(size_average=True)\r\n","                out_filters.append(1)\r\n","                models.append(model)\r\n","            elif block['type'] == 'reorg':\r\n","                stride = int(block['stride'])\r\n","                prev_filters = stride * stride * prev_filters\r\n","                out_filters.append(prev_filters)\r\n","                models.append(Reorg(stride))\r\n","            elif block['type'] == 'route':\r\n","                layers = block['layers'].split(',')\r\n","                ind = len(models)\r\n","                layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\r\n","                if len(layers) == 1:\r\n","                    prev_filters = out_filters[layers[0]]\r\n","                elif len(layers) == 2:\r\n","                    assert(layers[0] == ind - 1)\r\n","                    prev_filters = out_filters[layers[0]] + out_filters[layers[1]]\r\n","                out_filters.append(prev_filters)\r\n","                models.append(EmptyModule())\r\n","            elif block['type'] == 'shortcut':\r\n","                ind = len(models)\r\n","                prev_filters = out_filters[ind-1]\r\n","                out_filters.append(prev_filters)\r\n","                models.append(EmptyModule())\r\n","            elif block['type'] == 'connected':\r\n","                filters = int(block['output'])\r\n","                if block['activation'] == 'linear':\r\n","                    model = nn.Linear(prev_filters, filters)\r\n","                elif block['activation'] == 'leaky':\r\n","                    model = nn.Sequential(\r\n","                               nn.Linear(prev_filters, filters),\r\n","                               nn.LeakyReLU(0.1, inplace=True))\r\n","                elif block['activation'] == 'relu':\r\n","                    model = nn.Sequential(\r\n","                               nn.Linear(prev_filters, filters),\r\n","                               nn.ReLU(inplace=True))\r\n","                prev_filters = filters\r\n","                out_filters.append(prev_filters)\r\n","                models.append(model)\r\n","            elif block['type'] == 'region':\r\n","                loss = RegionLoss()\r\n","                anchors = block['anchors'].split(',')\r\n","                loss.anchors = [float(i) for i in anchors]\r\n","                loss.num_classes = int(block['classes'])\r\n","                loss.num_anchors = int(block['num'])\r\n","                loss.anchor_step = len(loss.anchors)//loss.num_anchors\r\n","                loss.object_scale = float(block['object_scale'])\r\n","                loss.noobject_scale = float(block['noobject_scale'])\r\n","                loss.class_scale = float(block['class_scale'])\r\n","                loss.coord_scale = float(block['coord_scale'])\r\n","                out_filters.append(prev_filters)\r\n","                models.append(loss)\r\n","            else:\r\n","                print('unknown type %s' % (block['type']))\r\n","    \r\n","        return models\r\n","\r\n","    def load_weights(self, weightfile):\r\n","        fp = open(weightfile, 'rb')\r\n","        header = np.fromfile(fp, count=4, dtype=np.int32)\r\n","        self.header = torch.from_numpy(header)\r\n","        self.seen = self.header[3]\r\n","        buf = np.fromfile(fp, dtype = np.float32)\r\n","        fp.close()\r\n","\r\n","        start = 0\r\n","        ind = -2\r\n","        for block in self.blocks:\r\n","            if start >= buf.size:\r\n","                break\r\n","            ind = ind + 1\r\n","            if block['type'] == 'net':\r\n","                continue\r\n","            elif block['type'] == 'convolutional':\r\n","                model = self.models[ind]\r\n","                batch_normalize = int(block['batch_normalize'])\r\n","                if batch_normalize:\r\n","                    start = load_conv_bn(buf, start, model[0], model[1])\r\n","                else:\r\n","                    start = load_conv(buf, start, model[0])\r\n","            elif block['type'] == 'connected':\r\n","                model = self.models[ind]\r\n","                if block['activation'] != 'linear':\r\n","                    start = load_fc(buf, start, model[0])\r\n","                else:\r\n","                    start = load_fc(buf, start, model)\r\n","            elif block['type'] == 'maxpool':\r\n","                pass\r\n","            elif block['type'] == 'reorg':\r\n","                pass\r\n","            elif block['type'] == 'route':\r\n","                pass\r\n","            elif block['type'] == 'shortcut':\r\n","                pass\r\n","            elif block['type'] == 'region':\r\n","                pass\r\n","            elif block['type'] == 'avgpool':\r\n","                pass\r\n","            elif block['type'] == 'softmax':\r\n","                pass\r\n","            elif block['type'] == 'cost':\r\n","                pass\r\n","            else:\r\n","                print('unknown type %s' % (block['type']))\r\n","\r\n","\r\n","    def save_weights(self, outfile, cutoff=0):\r\n","        if cutoff <= 0:\r\n","            cutoff = len(self.blocks)-1\r\n","\r\n","        fp = open(outfile, 'wb')\r\n","        self.header[3] = self.seen\r\n","        header = self.header\r\n","        header.numpy().tofile(fp)\r\n","\r\n","        ind = -1\r\n","        for blockId in range(1, cutoff+1):\r\n","            ind = ind + 1\r\n","            block = self.blocks[blockId]\r\n","            if block['type'] == 'convolutional':\r\n","                model = self.models[ind]\r\n","                batch_normalize = int(block['batch_normalize'])\r\n","                if batch_normalize:\r\n","                    save_conv_bn(fp, model[0], model[1])\r\n","                else:\r\n","                    save_conv(fp, model[0])\r\n","            elif block['type'] == 'connected':\r\n","                model = self.models[ind]\r\n","                if block['activation'] != 'linear':\r\n","                    save_fc(fc, model)\r\n","                else:\r\n","                    save_fc(fc, model[0])\r\n","            elif block['type'] == 'maxpool':\r\n","                pass\r\n","            elif block['type'] == 'reorg':\r\n","                pass\r\n","            elif block['type'] == 'route':\r\n","                pass\r\n","            elif block['type'] == 'shortcut':\r\n","                pass\r\n","            elif block['type'] == 'region':\r\n","                pass\r\n","            elif block['type'] == 'avgpool':\r\n","                pass\r\n","            elif block['type'] == 'softmax':\r\n","                pass\r\n","            elif block['type'] == 'cost':\r\n","                pass\r\n","            else:\r\n","                print('unknown type %s' % (block['type']))\r\n","        fp.close()\r\n","\r\n","if __name__ == \"__main__\":\r\n","    model = Darknet(\"cfg/yolo.cfg\").cuda()\r\n","    # print(model)\r\n","    model.load_weights(\"yolo.weights\")\r\n","    data = torch.randn(16, 3, 480, 256).cuda()\r\n","    output = model(data)\r\n","    print(output.size()) # 24,425,7,7\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([16, 425, 15, 8])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZyN0JDiBw2w7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610013411397,"user_tz":-420,"elapsed":767,"user":{"displayName":"Vu Nghia","photoUrl":"","userId":"06396789043579285095"}},"outputId":"2e1b4155-5d17-4354-df9f-a9ede6080cbc"},"source":["from torchsummary import summary\r\n","summary(model, (3,480,256))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 480, 256]             864\n","       BatchNorm2d-2         [-1, 32, 480, 256]              64\n","         LeakyReLU-3         [-1, 32, 480, 256]               0\n","         MaxPool2d-4         [-1, 32, 240, 128]               0\n","            Conv2d-5         [-1, 64, 240, 128]          18,432\n","       BatchNorm2d-6         [-1, 64, 240, 128]             128\n","         LeakyReLU-7         [-1, 64, 240, 128]               0\n","         MaxPool2d-8          [-1, 64, 120, 64]               0\n","            Conv2d-9         [-1, 128, 120, 64]          73,728\n","      BatchNorm2d-10         [-1, 128, 120, 64]             256\n","        LeakyReLU-11         [-1, 128, 120, 64]               0\n","           Conv2d-12          [-1, 64, 120, 64]           8,192\n","      BatchNorm2d-13          [-1, 64, 120, 64]             128\n","        LeakyReLU-14          [-1, 64, 120, 64]               0\n","           Conv2d-15         [-1, 128, 120, 64]          73,728\n","      BatchNorm2d-16         [-1, 128, 120, 64]             256\n","        LeakyReLU-17         [-1, 128, 120, 64]               0\n","        MaxPool2d-18          [-1, 128, 60, 32]               0\n","           Conv2d-19          [-1, 256, 60, 32]         294,912\n","      BatchNorm2d-20          [-1, 256, 60, 32]             512\n","        LeakyReLU-21          [-1, 256, 60, 32]               0\n","           Conv2d-22          [-1, 128, 60, 32]          32,768\n","      BatchNorm2d-23          [-1, 128, 60, 32]             256\n","        LeakyReLU-24          [-1, 128, 60, 32]               0\n","           Conv2d-25          [-1, 256, 60, 32]         294,912\n","      BatchNorm2d-26          [-1, 256, 60, 32]             512\n","        LeakyReLU-27          [-1, 256, 60, 32]               0\n","        MaxPool2d-28          [-1, 256, 30, 16]               0\n","           Conv2d-29          [-1, 512, 30, 16]       1,179,648\n","      BatchNorm2d-30          [-1, 512, 30, 16]           1,024\n","        LeakyReLU-31          [-1, 512, 30, 16]               0\n","           Conv2d-32          [-1, 256, 30, 16]         131,072\n","      BatchNorm2d-33          [-1, 256, 30, 16]             512\n","        LeakyReLU-34          [-1, 256, 30, 16]               0\n","           Conv2d-35          [-1, 512, 30, 16]       1,179,648\n","      BatchNorm2d-36          [-1, 512, 30, 16]           1,024\n","        LeakyReLU-37          [-1, 512, 30, 16]               0\n","           Conv2d-38          [-1, 256, 30, 16]         131,072\n","      BatchNorm2d-39          [-1, 256, 30, 16]             512\n","        LeakyReLU-40          [-1, 256, 30, 16]               0\n","           Conv2d-41          [-1, 512, 30, 16]       1,179,648\n","      BatchNorm2d-42          [-1, 512, 30, 16]           1,024\n","        LeakyReLU-43          [-1, 512, 30, 16]               0\n","        MaxPool2d-44           [-1, 512, 15, 8]               0\n","           Conv2d-45          [-1, 1024, 15, 8]       4,718,592\n","      BatchNorm2d-46          [-1, 1024, 15, 8]           2,048\n","        LeakyReLU-47          [-1, 1024, 15, 8]               0\n","           Conv2d-48           [-1, 512, 15, 8]         524,288\n","      BatchNorm2d-49           [-1, 512, 15, 8]           1,024\n","        LeakyReLU-50           [-1, 512, 15, 8]               0\n","           Conv2d-51          [-1, 1024, 15, 8]       4,718,592\n","      BatchNorm2d-52          [-1, 1024, 15, 8]           2,048\n","        LeakyReLU-53          [-1, 1024, 15, 8]               0\n","           Conv2d-54           [-1, 512, 15, 8]         524,288\n","      BatchNorm2d-55           [-1, 512, 15, 8]           1,024\n","        LeakyReLU-56           [-1, 512, 15, 8]               0\n","           Conv2d-57          [-1, 1024, 15, 8]       4,718,592\n","      BatchNorm2d-58          [-1, 1024, 15, 8]           2,048\n","        LeakyReLU-59          [-1, 1024, 15, 8]               0\n","           Conv2d-60          [-1, 1024, 15, 8]       9,437,184\n","      BatchNorm2d-61          [-1, 1024, 15, 8]           2,048\n","        LeakyReLU-62          [-1, 1024, 15, 8]               0\n","           Conv2d-63          [-1, 1024, 15, 8]       9,437,184\n","      BatchNorm2d-64          [-1, 1024, 15, 8]           2,048\n","        LeakyReLU-65          [-1, 1024, 15, 8]               0\n","           Conv2d-66           [-1, 64, 30, 16]          32,768\n","      BatchNorm2d-67           [-1, 64, 30, 16]             128\n","        LeakyReLU-68           [-1, 64, 30, 16]               0\n","            Reorg-69           [-1, 256, 15, 8]               0\n","           Conv2d-70          [-1, 1024, 15, 8]      11,796,480\n","      BatchNorm2d-71          [-1, 1024, 15, 8]           2,048\n","        LeakyReLU-72          [-1, 1024, 15, 8]               0\n","           Conv2d-73           [-1, 425, 15, 8]         435,625\n","================================================================\n","Total params: 50,962,889\n","Trainable params: 50,962,889\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.41\n","Forward/backward pass size (MB): 277.42\n","Params size (MB): 194.41\n","Estimated Total Size (MB): 473.23\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fJ9UhVw3I2u","executionInfo":{"status":"ok","timestamp":1610013431249,"user_tz":-420,"elapsed":978,"user":{"displayName":"Vu Nghia","photoUrl":"","userId":"06396789043579285095"}},"outputId":"604d51ca-d431-4445-a6d2-f95eca83648e"},"source":["model.print_network()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["layer     filters    size              input                output\n","    0 conv     32  3 x 3 / 1   224 x 224 x   3   ->   224 x 224 x  32\n","    1 max          2 x 2 / 2   224 x 224 x  32   ->   112 x 112 x  32\n","    2 conv     64  3 x 3 / 1   112 x 112 x  32   ->   112 x 112 x  64\n","    3 max          2 x 2 / 2   112 x 112 x  64   ->    56 x  56 x  64\n","    4 conv    128  3 x 3 / 1    56 x  56 x  64   ->    56 x  56 x 128\n","    5 conv     64  1 x 1 / 1    56 x  56 x 128   ->    56 x  56 x  64\n","    6 conv    128  3 x 3 / 1    56 x  56 x  64   ->    56 x  56 x 128\n","    7 max          2 x 2 / 2    56 x  56 x 128   ->    28 x  28 x 128\n","    8 conv    256  3 x 3 / 1    28 x  28 x 128   ->    28 x  28 x 256\n","    9 conv    128  1 x 1 / 1    28 x  28 x 256   ->    28 x  28 x 128\n","   10 conv    256  3 x 3 / 1    28 x  28 x 128   ->    28 x  28 x 256\n","   11 max          2 x 2 / 2    28 x  28 x 256   ->    14 x  14 x 256\n","   12 conv    512  3 x 3 / 1    14 x  14 x 256   ->    14 x  14 x 512\n","   13 conv    256  1 x 1 / 1    14 x  14 x 512   ->    14 x  14 x 256\n","   14 conv    512  3 x 3 / 1    14 x  14 x 256   ->    14 x  14 x 512\n","   15 conv    256  1 x 1 / 1    14 x  14 x 512   ->    14 x  14 x 256\n","   16 conv    512  3 x 3 / 1    14 x  14 x 256   ->    14 x  14 x 512\n","   17 max          2 x 2 / 2    14 x  14 x 512   ->     7 x   7 x 512\n","   18 conv   1024  3 x 3 / 1     7 x   7 x 512   ->     7 x   7 x1024\n","   19 conv    512  1 x 1 / 1     7 x   7 x1024   ->     7 x   7 x 512\n","   20 conv   1024  3 x 3 / 1     7 x   7 x 512   ->     7 x   7 x1024\n","   21 conv    512  1 x 1 / 1     7 x   7 x1024   ->     7 x   7 x 512\n","   22 conv   1024  3 x 3 / 1     7 x   7 x 512   ->     7 x   7 x1024\n","   23 conv   1024  3 x 3 / 1     7 x   7 x1024   ->     7 x   7 x1024\n","   24 conv   1024  3 x 3 / 1     7 x   7 x1024   ->     7 x   7 x1024\n","   25 route  16\n","   26 conv     64  1 x 1 / 1    14 x  14 x 512   ->    14 x  14 x  64\n","   27 reorg              / 2    14 x  14 x  64   ->     7 x   7 x 256\n","   28 route  27 24\n","   29 conv   1024  3 x 3 / 1     7 x   7 x1280   ->     7 x   7 x1024\n","   30 conv    425  1 x 1 / 1     7 x   7 x1024   ->     7 x   7 x 425\n","   31 detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BnRo8YPm4LPY","executionInfo":{"status":"ok","timestamp":1610013469934,"user_tz":-420,"elapsed":725,"user":{"displayName":"Vu Nghia","photoUrl":"","userId":"06396789043579285095"}},"outputId":"3b4a4766-d487-49a2-b3c2-1ad362be732b"},"source":["type(model.models)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.nn.modules.container.ModuleList"]},"metadata":{"tags":[]},"execution_count":11}]}]}